<div align="center">
 
<h3>AI-powered multi-agentic system for medical diagnosis and assistance</h3>


<!-- ![PyTorch - Version](https://img.shields.io/badge/PYTORCH-2.0+-red?style=for-the-badge&logo=pytorch) -->
![Python - Version](https://img.shields.io/badge/PYTHON-3.11+-blue?style=for-the-badge&logo=python&logoColor=white)
![LangGraph - Version](https://img.shields.io/badge/LangGraph-0.3+-teal?style=for-the-badge&logo=langgraph)
![LangChain - Version](https://img.shields.io/badge/LangChain-0.3+-teal?style=for-the-badge&logo=langchain)
![Qdrant Client - Version](https://img.shields.io/badge/Qdrant-1.13+-red?style=for-the-badge&logo=qdrant)
![Pydantic - Version](https://img.shields.io/badge/Pydantic-2.10+-red?style=for-the-badge&logo=pydantic)
![FastAPI - Version](https://img.shields.io/badge/FastAPI-0.115+-teal?style=for-the-badge&logo=fastapi)
![Docling - Version](https://img.shields.io/badge/Docling-3.1+-orange?style=for-the-badge&logo=docling)
[![Generic badge](https://img.shields.io/badge/License-Apache-<COLOR>.svg?style=for-the-badge)](https://github.com/souvikmajumder26/Multi-Agent-Medical-Assistant/blob/main/LICENSE) 
[![GitHub Issues](https://img.shields.io/github/issues/souvikmajumder26/Multi-Agent-Medical-Assistant.svg?style=for-the-badge)](https://github.com/souvikmajumder26/Multi-Agent-Medical-Assistant/issues)
![Contributions welcome](https://img.shields.io/badge/contributions-welcome-orange.svg?style=for-the-badge)

</div>

----
 
## üìö Table of Contents
- [Overview](#overview)
- [Demo](#demo)
- [Technical Flow Chart](#technical-flowchart)
- [Key Features](#key-features)
- [Tech Stack](#technology-stack)
- [Installation and Setup](#installation-setup)
  - [Using Docker](#docker-setup)
  - [Manual Installation](#manual-setup)
- [License](#license)



----

## üìå Overview <a name="overview"></a>

The **Multi-Agent Medical Assistant** is an **AI-powered chatbot** designed to assist with **medical diagnosis, research, and patient interactions**.  

 **Powered by Multi-Agent Intelligence**, this system integrates:  
- **Large Language Models (LLMs)**  
- **Computer Vision Models** for medical imaging analysis  
- **Retrieval-Augmented Generation (RAG)** leveraging vector databases  
- **Real-time Web Search** for up-to-date medical insights  
- **Human-in-the-Loop Validation** to verify AI-based medical image diagnoses  

### **What You‚Äôll Learn from This Project**  
- **Multi-Agent Orchestration** with structured graph workflows  
- **Advanced RAG Techniques** ‚Äì hybrid retrieval, semantic chunking, and vector search  
-  **Confidence-Based Routing** & **Agent-to-Agent Handoff**  
-  **Scalable, Production-Ready AI with Modularized Code & Robust Exception Handling**  
 

---

## üí´ Demo <a name="demo"></a>


https://github.com/user-attachments/assets/d27d4a2e-1c7d-45e2-bbc5-b3d95ccd5b35



---

## üõ°Ô∏è Technical Flow Chart  <a name="technical-flowchart"></a>

![Technical Flow Chart](assets/final_medical_assistant_flowchart_light_rounded.png)

---

<!-- ## Key Features  <a name="key-features"></a>
- **Multi-Agent System** ‚Äì Separate agents handle different tasks (diagnosis, retrieval, reasoning, etc.).  
- **RAG-based Retrieval** ‚Äì Uses Qdrant for vector search & hybrid retrieval techniques.  
-  **Medical Image Analysis** ‚Äì Supports **brain tumor segmentation, chest X-ray disease detection, and skin lesion classification**.  
- **Web Search Agent** ‚Äì Fetches the latest medical research when required.  
- **Confidence Score Check** ‚Äì Ensures high accuracy with log probability-based verification.  
- **Speech-to-Text & Text-to-Speech** ‚Äì Uses **Eleven Labs API** for voice interactions.  
-  **Human-in-the-Loop Verification** ‚Äì Medical professionals validate the AI‚Äôs results before final output.  
- **Intuitive UI** ‚Äì Built for seamless user experience.  

---

##  Tech Stack  <a name="tech-stack"></a>
-  **Backend**: FastAPI  
- **Multi-Agent Orchestration**: LangGraph + LangChain   
- **Vector Database**: Qdrant (for retrieval-augmented generation)   
- **Medical Image Analysis**: Computer vision models (Brain Tumor - Semantic Segmentation, Chest X-ray - Object Detection, Skin Lesion - Classification)  
- **Speech Processing**: Eleven Labs API  
- **UI**: HTML, CSS, JS üåê  
- **Deployment**: Docker    -->

## ‚ú® Key Features  <a name="key-features"></a>

-  **Multi-Agent Architecture** : Specialized agents working in harmony to handle diagnosis, information retrieval, reasoning, and more

-  **Advanced Agentic RAG Retrieval System** :

  - Docling based parsing to extract text, tables, and images from PDFs.
  - Embedding markdown formatted text, tables and LLM based image summaries.
  - LLM based semantic chunking with structural boundary awareness.
  - LLM based query expansion with related medical domain terms.
  - Qdrant hybrid search combining BM25 sparse keyword search along with dense embedding vector search.
  - HuggingFace Cross-Encoder based reranking of retrieved document chunks for accurate LLM reponses.
  - Input-output guardrails to ensure safe and relevant responses.
  - Links to source documents and images present in reference document chunks provided with reponse.
  - Confidence-based agent-to-agent handoff between RAG and Web Search to prevent hallucinations.

-  **Medical Imaging Analysis**  
  - Chest X-ray Disease Classification
  - Skin Lesion Segmentation

-  **Real-time Research Integration** : Web search agent that retrieves the latest medical research papers and findings

-  **Confidence-Based Verification** : Log probability analysis ensures high accuracy in medical recommendations

-  **Voice Interaction Capabilities** : Seamless speech-to-text and text-to-speech powered by Eleven Labs API

-  **Expert Oversight System** : Human-in-the-loop verification by medical professionals before finalizing outputs

-  **Input & Output Guardrails** : Ensures safe, unbiased, and reliable medical responses while filtering out harmful or misleading content

-  **Intuitive User Interface** : Designed for healthcare professionals with minimal technical expertise

> [!NOTE]  
> Upcoming features:
> 1. Brain Tumor Medical Computer Vision model integration.


---

##  Technology Stack  <a name="technology-stack"></a>

| Component | Technologies |
|-----------|-------------|
| üîπ **Backend Framework** | FastAPI |
| üîπ **Agent Orchestration** | LangGraph |
| üîπ **Document Parsing** | Docling |
| üîπ **Knowledge Storage** | Qdrant Vector Database |
| üîπ **Medical Imaging** | Computer Vision Models | 
| | ‚Ä¢ Chest X-ray: Image Classification (PyTorch) |
| | ‚Ä¢ Skin Lesion: Semantic Segmentation (PyTorch) |
| üîπ **Guardrails** | LangChain |
| üîπ **Speech Processing** | Eleven Labs API |
| üîπ **Frontend** | HTML, CSS, JavaScript |
| üîπ **Deployment** | Docker, GitHub Actions CI/CD |

---

##  Installation & Setup  <a name="installation-setup"></a>

## üìå Option 1: Using Docker  <a name="docker-setup"></a>

### Prerequisites:

- [Docker](https://docs.docker.com/get-docker/) installed on your system
- API keys for the required services

### 1Ô∏è‚É£ Clone the Repository
```bash
git clone https://github.com/souvikmajumder26/Multi-Agent-Medical-Assistant.git
cd Multi-Agent-Medical-Assistant
```

### 2Ô∏è‚É£ Create Environment File
- Create a `.env` file in the root directory and add the following API keys:

> [!WARNING]  
> Ensure the API keys in the `.env` file are correct and have the necessary permissions.
> No trailing whitespaces after variable names.

```bash
# LLM Configuration (Azure Open AI - gpt-4o used in development)
# If using any other LLM API key or local LLM, appropriate code modification is required
deployment_name= 
model_name=gpt-4o
azure_endpoint=
openai_api_key=
openai_api_version=

# Embedding Model Configuration (Azure Open AI - text-embedding-ada-002 used in development)
# If using any other embedding model, appropriate code modification is required
embedding_deployment_name=
embedding_model_name=text-embedding-ada-002
embedding_azure_endpoint=
embedding_openai_api_key=
embedding_openai_api_version=

# Speech API Key (Free credits available with new Eleven Labs Account)
ELEVEN_LABS_API_KEY=

# Web Search API Key (Free credits available with new Tavily Account)
TAVILY_API_KEY=

# Hugging Face Token - using reranker model "ms-marco-TinyBERT-L-6"
HUGGINGFACE_TOKEN=

# (OPTIONAL) If using Qdrant server version, local does not require API key
QDRANT_URL=
QDRANT_API_KEY=
```

### 3Ô∏è‚É£ Build the Docker Image
```bash
docker build -t medical-assistant .
```

### 4Ô∏è‚É£ Run the Docker Container
```bash
docker run -d --name medical-assistant-app -p 8000:8000 --env-file .env medical-assistant
```
The application will be available at: [http://localhost:8000](http://localhost:8000)

### 5Ô∏è‚É£ Ingest Data into Vector DB from Docker Container

- To ingest a single document:
```bash
docker exec medical-assistant-app python ingest_rag_data.py --file ./data/raw/brain_tumors_ucni.pdf
```

- To ingest multiple documents from a directory:
```bash
docker exec medical-assistant-app python ingest_rag_data.py --dir ./data/raw
```

### Managing the Container:

#### Stop the Container
```bash
docker stop medical-assistant-app
```

#### Start the Container
```bash
docker start medical-assistant-app
```

#### View Logs
```bash
docker logs medical-assistant-app
```

#### Remove the Container
```bash
docker rm medical-assistant-app
```

### Troubleshooting:

#### Container Health Check
The container includes a health check that monitors the application status. You can check the health status with:
```bash
docker inspect --format='{{.State.Health.Status}}' medical-assistant-app
```

#### Container Not Starting
If the container fails to start, check the logs for errors:
```bash
docker logs medical-assistant-app
```


## üìå Option 2: Without Using Docker  <a name="manual-setup"></a>

### 1Ô∏è‚É£ Clone the Repository  
```bash  
git clone https://github.com/souvikmajumder26/Multi-Agent-Medical-Assistant.git  
cd Multi-Agent-Medical-Assistant  
```

### 2Ô∏è‚É£ Create & Activate Virtual Environment  
- If using conda:
```bash
conda create --name <environment-name> python=3.11
conda activate <environment-name>
```
- If using python venv:
```bash
python -m venv <environment-name>
source <environment-name>/bin/activate  # For Mac/Linux
<environment-name>\Scripts\activate     # For Windows  
```

### 3Ô∏è‚É£ Install Dependencies  

> [!IMPORTANT]  
> ffmpeg is required for speech service to work.

- If using conda:
```bash
conda install -c conda-forge ffmpeg
```
```bash
pip install -r requirements.txt  
```
- If using python venv:
```bash
winget¬†install ffmpeg
```
```bash
pip install -r requirements.txt  
```

### 4Ô∏è‚É£ Set Up API Keys  
- Create a `.env` file and add the required API keys as shown in `Option 1`.

### 5Ô∏è‚É£ Run the Application  
- Run the following command in the activate environment.

```bash
python app.py
```
The application will be available at: [http://localhost:8000](http://localhost:8000)

### 6Ô∏è‚É£ Ingest additional data into the Vector DB
Run any one of the following commands as required.
- To ingest one document at a time:
```bash
python ingest_rag_data.py --file ./data/raw/brain_tumors_ucni.pdf
```
- To ingest multiple documents from a directory:
```bash
python ingest_rag_data.py --dir ./data/raw
```

---

## ‚öñÔ∏è License  <a name="license"></a>
This project is licensed under the **Apache-2.0 License**. See the [LICENSE](LICENSE) file for details.  

---


